{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > O algoritmo de florestas aleatórias cria várias árvores de decisão e as combina para obter uma predição com maior acurácia e com maior estabilidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Uma desvantagem do uso de uma única árvore de decisão é que as árvores de decisão tendem a ser mais ajustadas aos dados de treinamento. Como o próprio nome sugere, uma floresta aleatória cria muitas árvores de decisão individuais em um conjunto de treinamento, geralmente da ordem de dezenas ou centenas de árvores. A idéia é que cada uma das árvores em uma floresta aleatória seja razoavelmente bem em prever os valores-alvo no conjunto de treinamento, mas também deve ser construída para ser diferente de alguma forma das outras árvores da floresta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    1 - Pode ser utilizado para tarefas de classificação e também de regressão. Eles podem ser usados ​​como classificadores através da classe sklearn RandomForestClassifier ou para regressão usando a classe RandomForestRegressor.\n",
    "    \n",
    "    2 - Algoritmo de aprendizagem supervisionada\n",
    "    \n",
    "    3 - Importância das Características (features): Grande qualidade das florestas aleatórias é a facilidade para se medir a importância relativa de cada característica (feature) para a predição. Sklearn provê uma excelente ferramenta para isto, que mede a importancia das características analisando quantos nodos das árvores, que usam uma dada característica, reduzem impureza geral da floresta. Ele calcula este valor automaticamente para cada característica após o treinamento e normaliza os resultados para que a soma de todas as importancias seja igual a 1. Através da inspeção da importância das características, você pode decidir quais características deixar de fora do modelo, já que eles não contribuem o suficiente ou nada para o processo de predição. Isto é importante, porque uma regra geral em aprendizagem de máquina é que quanto mais características você tem, mais provavelmente seu modelo irá sofrer de superajuste (overfitting) e vice versa.\n",
    "    \n",
    "    4 - Depois que um modelo de floresta aleatória é treinado, ele prediz o valor alvo para novas instâncias. Para tarefas de regressão, a previsão geral é normalmente a média das previsões individuais da árvore.\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hiperparâmetros Importantes:\n",
    "Os parâmetros no Floresta Aleatória são utilizados ou para aumentar o poder preditivo do modelo ou para tornar o modelo mais rápido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. Aumentar o poder preditivo:</b>\n",
    "\n",
    "   <b>n_estimators:</b> Indica o número de árvores construídas pelo algoritmo antes de tomar uma votação ou fazer uma média de predições. Em geral, uma quantidade elevada de árvores aumenta a performance e torna as predições mais estáveis, mas também torna a computação mais lenta.O valor padrão para n_estimators é 10 e aumentar esse número para conjuntos de dados maiores é quase certamente uma boa idéia.\n",
    "     \n",
    "   <b>max_features:</b> Indica o número máximo de características a serem utilizadas pelo Floresta Aleatória na construção de uma dada árvore. O modelo de floresta aleatória é bastante sensível ao parâmetro max_features.Se Max_Features for  definido como 1, a floresta aleatória é limitada a executar uma divisão no recurso único que foi selecionado aleatoriamente, em vez de ser capaz de realizar a melhor divisão em várias variáveis. Isso significa que as árvores (na floresta) provavelmente serão muito diferentes umas das outras e possivelmente com muitos níveis, a fim de produzir um bom ajuste aos dados. Por outro lado, se Max_features for alto, próximo ao número total de recursos que cada instância possui, as árvores na floresta tenderão a ser semelhantes e provavelmente exigirão menos níveis para ajustar os dados usando os recursos mais informativos. \n",
    "     \n",
    "  <b>min_sample_leaf:</b> Indica o número mínimo de folhas que devem existir em uma dada árvore.\n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "<b>2. Aumentar a velocidade do modelo:</b>\n",
    "\n",
    "   <b>n_jobs:</b> Informa quantos processadores o algoritmo pode utilizar. Se ele tiver valor 1, pode utilizar apenas um processador. O valor -1 significa que não há limite na quantidade de processadores a ser utilizado.\n",
    "   \n",
    "   <b>random_state:</b> Torna o resultado do modelo replicável. O modelo será produzido do mesmo modo se ele tiver um valor definido de random_state e se forem utilizados os mesmos parâmetros com o mesmos dados de treinamento.\n",
    "   \n",
    "   <b>oob_score:</b>(também chamado de oob sampling), que é um método de validação cruzada para floresta aleatória. Neste tipo de amostragem (sampling), cerca de um terço dos dados não é utilizado no treinamento e pode ser utilizado para avaliar a performance. Estas amostras são chamadas out of the bag samples. É uma técnica similar ao método de validação cruzada leave one out, mas sem nenhum custo computacional extra.\n",
    "\n",
    "https://medium.com/machina-sapiens/o-algoritmo-da-floresta-aleat%C3%B3ria-3545f6babdf8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(r'C:\\Users\\gizel\\Documents\\PUCMG\\PUC_MG_Disciplinas\\PUC_MG_Disciplinas\\04 - Machine Learning\\Unidade 3 - Aprendizado Supervisionado Classificação e Regressão/dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 61)\n",
      "Index(['Atributo_1', 'Atributo_2', 'Atributo_3', 'Atributo_4', 'Atributo_5',\n",
      "       'Atributo_6', 'Atributo_7', 'Atributo_8', 'Atributo_9', 'Atributo_10',\n",
      "       'Atributo_11', 'Atributo_12', 'Atributo_13', 'Atributo_14',\n",
      "       'Atributo_15', 'Atributo_16', 'Atributo_17', 'Atributo_18',\n",
      "       'Atributo_19', 'Atributo_20', 'Atributo_21', 'Atributo_22',\n",
      "       'Atributo_23', 'Atributo_24', 'Atributo_25', 'Atributo_26',\n",
      "       'Atributo_27', 'Atributo_28', 'Atributo_29', 'Atributo_30',\n",
      "       'Atributo_31', 'Atributo_32', 'Atributo_33', 'Atributo_34',\n",
      "       'Atributo_35', 'Atributo_36', 'Atributo_37', 'Atributo_38',\n",
      "       'Atributo_39', 'Atributo_40', 'Atributo_41', 'Atributo_42',\n",
      "       'Atributo_43', 'Atributo_44', 'Atributo_45', 'Atributo_46',\n",
      "       'Atributo_47', 'Atributo_48', 'Atributo_49', 'Atributo_50',\n",
      "       'Atributo_51', 'Atributo_52', 'Atributo_53', 'Atributo_54',\n",
      "       'Atributo_55', 'Atributo_56', 'Atributo_57', 'Atributo_58',\n",
      "       'Atributo_59', 'Atributo_60', 'Classe'],\n",
      "      dtype='object')\n",
      "['Rocha' 'Mina']\n"
     ]
    }
   ],
   "source": [
    "sonar = pd.read_excel('sonar.xlsx')\n",
    "\n",
    "print(sonar.shape)\n",
    "print(sonar.keys())\n",
    "print(sonar['Classe'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atributo_1</th>\n",
       "      <th>Atributo_2</th>\n",
       "      <th>Atributo_3</th>\n",
       "      <th>Atributo_4</th>\n",
       "      <th>Atributo_5</th>\n",
       "      <th>Atributo_6</th>\n",
       "      <th>Atributo_7</th>\n",
       "      <th>Atributo_8</th>\n",
       "      <th>Atributo_9</th>\n",
       "      <th>Atributo_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Atributo_51</th>\n",
       "      <th>Atributo_52</th>\n",
       "      <th>Atributo_53</th>\n",
       "      <th>Atributo_54</th>\n",
       "      <th>Atributo_55</th>\n",
       "      <th>Atributo_56</th>\n",
       "      <th>Atributo_57</th>\n",
       "      <th>Atributo_58</th>\n",
       "      <th>Atributo_59</th>\n",
       "      <th>Atributo_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Atributo_1  Atributo_2  Atributo_3  Atributo_4  Atributo_5  Atributo_6  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "       Atributo_7  Atributo_8  Atributo_9  Atributo_10  ...  Atributo_51  \\\n",
       "count  208.000000  208.000000  208.000000   208.000000  ...   208.000000   \n",
       "mean     0.121747    0.134799    0.178003     0.208259  ...     0.016069   \n",
       "std      0.061788    0.085152    0.118387     0.134416  ...     0.012008   \n",
       "min      0.003300    0.005500    0.007500     0.011300  ...     0.000000   \n",
       "25%      0.080900    0.080425    0.097025     0.111275  ...     0.008425   \n",
       "50%      0.106950    0.112100    0.152250     0.182400  ...     0.013900   \n",
       "75%      0.154000    0.169600    0.233425     0.268700  ...     0.020825   \n",
       "max      0.372900    0.459000    0.682800     0.710600  ...     0.100400   \n",
       "\n",
       "       Atributo_52  Atributo_53  Atributo_54  Atributo_55  Atributo_56  \\\n",
       "count   208.000000   208.000000   208.000000   208.000000   208.000000   \n",
       "mean      0.013420     0.010709     0.010941     0.009290     0.008222   \n",
       "std       0.009634     0.007060     0.007301     0.007088     0.005736   \n",
       "min       0.000800     0.000500     0.001000     0.000600     0.000400   \n",
       "25%       0.007275     0.005075     0.005375     0.004150     0.004400   \n",
       "50%       0.011400     0.009550     0.009300     0.007500     0.006850   \n",
       "75%       0.016725     0.014900     0.014500     0.012100     0.010575   \n",
       "max       0.070900     0.039000     0.035200     0.044700     0.039400   \n",
       "\n",
       "       Atributo_57  Atributo_58  Atributo_59  Atributo_60  \n",
       "count   208.000000   208.000000   208.000000   208.000000  \n",
       "mean      0.007820     0.007949     0.007941     0.006507  \n",
       "std       0.005785     0.006470     0.006181     0.005031  \n",
       "min       0.000300     0.000300     0.000100     0.000600  \n",
       "25%       0.003700     0.003600     0.003675     0.003100  \n",
       "50%       0.005950     0.005800     0.006400     0.005300  \n",
       "75%       0.010425     0.010350     0.010325     0.008525  \n",
       "max       0.035500     0.044000     0.036400     0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separação Dados de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pacote de treinamento: Pegando todas as colunas exceto a última coluna que possui os labels: 'Classe'\n",
    "\n",
    "X_train_ = sonar.iloc[:,0:(sonar.shape[1] - 1)]\n",
    "\n",
    "\n",
    "# LabelEnconder transforma apenas a última coluna \"Classe:['Rocha' 'Mina'] string em classe binária \n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train_ = le.fit_transform(sonar.iloc[:,(sonar.shape[1]-1)])\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_, y_train_, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com valores padrão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest, Sonar \n",
      "Acurácia no pacote de treinamento: 1.00\n",
      "Acurácia no pacote de teste: 0.75\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Random Forest, Sonar ')\n",
    "print('Acurácia no pacote de treinamento: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Acurácia no pacote de teste: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com max_features = 29, conseguimos um aumento importante na acurácia no pacote de testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest, Sonar \n",
      "Acurácia no pacote de treinamento: 1.00\n",
      "Acurácia no pacote de teste: 0.85\n"
     ]
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier(max_features = 29, random_state = 42)\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "print('Random Forest, Sonar ')\n",
    "print('Acurácia no pacote de treinamento: {:.2f}'\n",
    "     .format(clf2.score(X_train, y_train)))\n",
    "print('Acurácia no pacote de teste: {:.2f}'\n",
    "     .format(clf2.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando comparamos estes resultados obtidos acima com os resultados obtidos através de uma única árvore de decisão, mesmo utilizando-se os melhores parâmetros para esta árvore, podemos perceber o quanto as Florestas Aleatórias têm melhor desempenho para este conjunto de dados. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árvore de Decisão, Sonar \n",
      "Acurácia no pacote de treinamento: 1.00\n",
      "Acurácia no pacote de teste: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Construindo o modelo\n",
    "sonar_tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Treinando o modelo\n",
    "sonar_tree = sonar_tree_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Árvore de Decisão, Sonar ')\n",
    "print('Acurácia no pacote de treinamento: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Acurácia no pacote de teste: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
